#!/usr/bin/python3
import os
import signal
import sys
import time
from dev_global.env import PROG_NAME
from dev_global.path import LOG_FILE, PID_FILE, TASK_FILE, MANUAL
from libmysql_utils.mysql8 import mysqlBase, mysqlHeader
# from libmysql_utils.header import TASK_HEADER
from apscheduler.executors.pool import ThreadPoolExecutor
from apscheduler.jobstores.sqlalchemy import SQLAlchemyJobStore
from libtask.task_manager import taskManager, taskConfig
from threading import Thread
from libutils.log import neulog
from libutils.deamon import deamon
from libbasemodel.database_manager import event_initial_database


__version__ = '1.7.15'


TASK_HEADER = mysqlHeader(acc='task', pw='task2020', db='task')


def logfile_monitor(log_file):
    # A parallel programe which monitoring the log file.
    # If log file is not exists, it will create one and
    # relocalize the file.
    while True:
        if os.path.exists(log_file):
            time.sleep(10)
        else:
            create_file = open(log_file, 'a')
            create_file.close()
            with open(log_file, 'a') as write_null:
                os.dup2(write_null.fileno(), 1)
            with open(log_file, 'a') as error_null:
                os.dup2(error_null.fileno(), 2)
            neulog.info(f"{PROG_NAME} started with pid {os.getpid()}.")


def task_pipeline(taskfile=None, task_pipeline_name='Default'):
    # init task manager and main
    if not taskfile:
        raise FileNotFoundError(taskfile)
    mysql = mysqlBase(TASK_HEADER)
    jobstores = {
        'default': SQLAlchemyJobStore(tablename=f"{task_pipeline_name}_task_sched", engine=mysql.engine)
            }
    task_config = taskConfig(task_pipeline_name)
    task_manager = taskManager(
        task_config=task_config,
        taskfile=taskfile,
        task_manager_name=task_pipeline_name,
        jobstores=jobstores,
        executors={'default': ThreadPoolExecutor(20)},
        job_defaults={'max_instance': 5},
        options={"pool_pre_ping": True, "pool_recycle": 14400})
    task_manager.start()
    neulog.info(f"{PROG_NAME} started with pid {os.getpid()}.")
    while True:
        task_manager.task_report()
        task_manager.task_solver.load_event()
        task_list = task_manager.check_task_list()
        task_manager.task_manage(task_list)
        time.sleep(3600)


def main(pid_file: str, log_file: str, task_file: str, prog_name: str):
    deamon(pid_file, log_file, prog_name)
    LM = Thread(target=logfile_monitor, args=(log_file,), name='neu_lm', daemon=True)
    LM.start()
    task_pipeline(task_file, prog_name)


if __name__ == '__main__':
    # This is main function
    # Arguments format is like 'netrino args'
    # Neutrino receives args like start stop or other.
    if len(sys.argv) != 2:
        print(f"{PROG_NAME} start|stop|help")
        raise SystemExit(1)
    if sys.argv[1] == 'start':
        main(PID_FILE, LOG_FILE, TASK_FILE, 'neutrino')
    elif sys.argv[1] == 'stop':
        if os.path.exists(PID_FILE):
            sys.stdout.flush()
            with open(LOG_FILE, 'a') as write_null:
                os.dup2(write_null.fileno(), 1)
                neulog.info(f"{PROG_NAME} is stopped.")
            with open(PID_FILE) as f:
                os.kill(int(f.read()), signal.SIGTERM)
        else:
            neulog.error(f"{PROG_NAME} is not running.")
            raise SystemExit(1)
    elif sys.argv[1] == 'clear':
        with open(LOG_FILE, 'w') as f:
            pass
    elif sys.argv[1] == 'init':
        event_initial_database()
    elif sys.argv[1] == 'help':
        os.system(f"cat {MANUAL}")
        # print_info(MANUAL)
    elif sys.argv[1] == 'log':
        os.system(f"cat {LOG_FILE}")
        # print_info(LOG_FILE)
    elif sys.argv[1] == 'version':
        print(__version__)
    else:
        print('Unknown command {!r}'.format(sys.argv[1]))
        raise SystemExit(1)
